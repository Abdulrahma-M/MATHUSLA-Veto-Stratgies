{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01e98b66-3653-462b-b9e8-e921aff824e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "ana_helper_path = \"/project/def-mdiamond/tomren/jupyter/Mu_helper/muhelper/\"\n",
    "sys.path.append(ana_helper_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9126952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.24/06\n",
      "\n",
      "\u001b[1mRooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby\u001b[0m \n",
      "                Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University\n",
      "                All rights reserved, please read http://roofit.sourceforge.net/license.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# import analyzer\n",
    "import importlib\n",
    "from importlib import reload\n",
    "import os, sys, glob, warnings, glob\n",
    "import scipy\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import joblib\n",
    "# from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "import copy as cp\n",
    "\n",
    "# ROOT\n",
    "import ROOT as root\n",
    "\n",
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import collections, colors, transforms\n",
    "\n",
    "from pylab import *\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "# %matplotlib widget\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# All other scripits\n",
    "import include_modules_root as rt\n",
    "# Figure configuration are saved in this file include_figure_preset.py\n",
    "from include_figure_preset import * \n",
    "# Set Figure font family, fontsize, ticks, etc.\n",
    "plt_config(family=\"san-serif\", fontsize_multi=1) # or \"serif\", or an exact font name\n",
    "\n",
    "\n",
    "# Redefine a function to save figures with common settings \n",
    "fig_prefix = \"plots/\"    # It's good to keep figures in a separate folder. Can also be set to None.\n",
    "fig_format = \"jpg\"      # for multiple formats, e.g.: \"pdf,png\"\n",
    "SAVE_FIG = False         # Use this flag to turn the figure saving on or off, so that you don't need to modify all notebook to save figure.\n",
    "# You can then do `savefig(filename_without_extension)` to save your plots with these settings\n",
    "savefig = Save_fig(fig_prefix=fig_prefix, exts=fig_format, SAVE= SAVE_FIG, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60830d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure configuration are saved in this file include_figure_preset.py\n",
    "from include_figure_preset import * \n",
    "# Set Figure font family, fontsize, ticks, etc.\n",
    "plt_config(family=\"san-serif\", fontsize_multi=1) # or \"serif\", or an exact font name\n",
    "\n",
    "\n",
    "# Redefine a function to save figures with common settings \n",
    "fig_prefix = \"plots/\"    # It's good to keep figures in a separate folder. Can also be set to None.\n",
    "fig_format = \"jpg\"      # for multiple formats, e.g.: \"pdf,png\"\n",
    "SAVE_FIG = False         # Use this flag to turn the figure saving on or off, so that you don't need to modify all notebook to save figure.\n",
    "# You can then do `savefig(filename_without_extension)` to save your plots with these settings\n",
    "savefig = Save_fig(fig_prefix=fig_prefix, exts=fig_format, SAVE= SAVE_FIG, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46a1d2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR    = \"/project/rrg-mdiamond/tomren/mudata/background/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5cb20f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Universal names, Input file, output filenames, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ade86bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Get a list of filenames to process ---\n",
    "energy_list = [0.1, 0.2, 0.5, 1, 3, 10, 30, 100]\n",
    "name_list = [\"muon\", \"pion\", \"electron\"]\n",
    "name_list_latex = [\"$\\mu^-$\", \"$\\pi^+$\", \"$e^-$\"]\n",
    "pdgid_list = [13, 211, 11]\n",
    "\n",
    "INDS_PAR = [2,0,3,6,4,5] # from CMS coord to DET coord. \n",
    "PAR_LABELS=[\"$x_0$ [cm]\",\"$y_0$ [cm]\", \"$t_0$ [ns]\", \"$v_x$ [cm/ns]\", \"$v_y$ [cm/ns]\", \"$v_z$ [cm/ns]\"]\n",
    "PAR_LABELS_CMS=[\"$x_0$ [cm]\",\"$y_0$ [cm]\",\"$z_0$ [cm]\", \"$t_0$ [ns]\", \"$v_x$ [cm/ns]\", \"$v_y$ [cm/ns]\", \"$v_z$ [cm/ns]\"]\n",
    "PAR_LABELS_RAW=[\"x0\", \"y0\", \"z0\", \"t0\", \"vx\", \"vy\", \"vz\"]\n",
    "PAR_PLOT_RANGES=np.array([[-15,15],[-15,15],[-4,4],[-2,2], [-2,2], [-6,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7bddcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = {}\n",
    "\n",
    "for name in name_list:\n",
    "    file_list_temp = []\n",
    "    for energy in energy_list:\n",
    "        files=glob.glob(f\"{DATA_DIR}/{name}_{energy}_GeV/*/*/stat_seedmod.root\",)\n",
    "        #files=util.Utils.sortByExt(files)\n",
    "        if len(files)>=1:\n",
    "            file_list_temp.append(files[0])\n",
    "        if len(files)>1:\n",
    "            print(f\"More than one file for {name} at {energy} GeV\")\n",
    "    file_list[name] = file_list_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da96b5e0-72c8-4f2a-8f7b-5f18aef74955",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Detector Geometry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a09f14-c9ab-455e-9c57-705a87f6d110",
   "metadata": {},
   "outputs": [],
   "source": [
    "gap = 100\n",
    "module_height = 800\n",
    "BoxLimits = [  [-5000.0, 5000.0],  [6000.0 + 547, 8917.0 + 547],  [6895.1, 17000.0]]\n",
    "ModuleYLims=[[6547.0, 6547.0 + module_height], [6547.0 + module_height + gap, 6547.0 + 2*module_height + gap ], [6547.0 + 2*module_height + 2*gap,6547.0 + 3*module_height + 2*gap]] \n",
    "ModuleXLims = [ [-4950. + 1000.*n, -4050. + 1000*n] for n in range(10) ]\n",
    "ModuleZLims = [ [7000.  + 1000.*n,  7900. + 1000*n] for n in range(10) ]\n",
    "scintillator_height_all = 2.6 # 2cm +0.3*2Al case\n",
    "wall_gap = 1.0\n",
    "wall_gap2 = 100.0\n",
    "wall_height = 2600.0\n",
    "wall_start_y = ModuleYLims[0][0] - 3\n",
    "z_min_wall = ModuleZLims[0][0] - wall_gap - scintillator_height_all\n",
    "MODULE_Z_RANGE_CMS_cm = [70_00, 70_00+90_00]\n",
    "MODULE_Y_RANGE_CMS_cm = [85_47, 85_47+11_00]\n",
    "cm = 1\n",
    "LayerYLims= [[6547.0,6547.0+scintillator_height_all],\n",
    "            [6629.6,6629.6+scintillator_height_all],\n",
    "            [8547.0,8547.0+scintillator_height_all],\n",
    "            [8629.6,8629.6+scintillator_height_all],\n",
    "            [9132.2,9132.2+scintillator_height_all],\n",
    "            [9214.8,9214.8+scintillator_height_all],\n",
    "            [9297.4,9297.4+scintillator_height_all],\n",
    "            [9380.0,9380.0+scintillator_height_all],\n",
    "            [9462.6,9462.6+scintillator_height_all],\n",
    "            [9545.2,9545.2+scintillator_height_all]]\n",
    "ymin=LayerYLims[0][0] - 10\n",
    "ymax=LayerYLims[-1][1] + 10\n",
    "floor_midpoint = [(6547.0 + 6547.0+scintillator_height_all)/2,(6629.6 + 6629.6+scintillator_height_all)/2]\n",
    "wall_midpoint= [(ModuleZLims[0][0]- wall_gap -wall_gap2 - scintillator_height_all*1.5) ,(ModuleZLims[0][0] - wall_gap - scintillator_height_all/2.0)]\n",
    "xLims=[BoxLimits[0][0],BoxLimits[0][1]]\n",
    "yLims=[BoxLimits[1][0],BoxLimits[1][1]]\n",
    "zLims=[BoxLimits[2][0],BoxLimits[2][1]]\n",
    "\n",
    "\n",
    "\n",
    "bincenters=[0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "area_loss=[0.18302325581395348,\n",
    " 0.19174418604651164,\n",
    " 0.20046511627906977,\n",
    " 0.2091860465116279,\n",
    " 0.21790697674418605,\n",
    " 0.22662790697674418,\n",
    " 0.23534883720930233,\n",
    " 0.24406976744186046,\n",
    " 0.2527906976744186,\n",
    " 0.26151162790697674,\n",
    " 0.2702325581395349]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def inBox(hit):\n",
    "    x,y,z=hit[:3]\n",
    "    if x >= xLims[0] and x <= xLims[1]:\n",
    "        if y >= yLims[0] and y <= yLims[1]:\n",
    "            if z >= zLims[0] and z <= zLims[1]:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "\n",
    "def inGap(hit):\n",
    "    x,y,z = hit[:3]\n",
    "    if z < 7000:\n",
    "        for j in range(len(ModuleYLims)-1):\n",
    "            if  ModuleYLims[j][1] < y < ModuleYLims[j+1][0]:\n",
    "                return True    \n",
    "        for k in range(len(ModuleXLims)-1): \n",
    "            if  ModuleXLims[k][1] < x < ModuleXLims[k+1][0]:\n",
    "                return True\n",
    "        return False\n",
    "    elif y < 8547.0 and z >= 7000 :\n",
    "        for i in range(len(ModuleXLims)-1):\n",
    "            if  ModuleXLims[i][1] < x < ModuleXLims[i+1][0]:\n",
    "                return True\n",
    "            if  ModuleZLims[i][1] < z < ModuleZLims[i+1][0]:\n",
    "                return True\n",
    "        return False\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    \n",
    "def inModuleX(xVal):\n",
    "    for moduleN, moduleLims in enumerate(ModuleXLims):\n",
    "        if xVal > moduleLims[0] and xVal < moduleLims[1]:\n",
    "            return moduleN\n",
    "\n",
    "def inModuleZ(zVal):\n",
    "    for moduleN, moduleLims in enumerate(ModuleZLims):\n",
    "        if zVal > moduleLims[0] and zVal < moduleLims[1]:\n",
    "            return moduleN\n",
    "        \n",
    "def inModuleY(yVal):\n",
    "    for moduleN, moduleLims in enumerate(ModuleYLims):\n",
    "        if yVal > moduleLims[0] and yVal < moduleLims[1]:\n",
    "            return moduleN\n",
    "def inFW(hit):\n",
    "# returns the layer number given the y value \n",
    "# if hit is in the wall returns zero \n",
    "# non wall/floor hit inLayer(hit->y) > 2\n",
    "    yVal= hit[1]\n",
    "    zVal= hit[2]\n",
    "    if zVal < 7000:\n",
    "        return -1\n",
    "\n",
    "    scintillator_height_all = 2.6\n",
    "    LayerYLims= [[6547.0,6547.0+scintillator_height_all],\n",
    "                 [6629.6,6629.6+scintillator_height_all],\n",
    "                 [8547.0,8547.0+scintillator_height_all],\n",
    "                 [8629.6,8629.6+scintillator_height_all],\n",
    "                 [9132.2,9132.2+scintillator_height_all],\n",
    "                 [9214.8,9214.8+scintillator_height_all],\n",
    "                 [9297.4,9297.4+scintillator_height_all],\n",
    "                 [9380.0,9380.0+scintillator_height_all],\n",
    "                 [9462.6,9462.6+scintillator_height_all],\n",
    "                 [9545.2,9545.2+scintillator_height_all]]\n",
    "    for i in range(len(LayerYLims)):\n",
    "        if yVal > LayerYLims[i][0] and yVal < LayerYLims[i][1]:\n",
    "            return i+1\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "def track_event_sort(data):\n",
    "    event_pointer=[]\n",
    "    for ind in data[\"event_ind\"]:\n",
    "        ind_list=[]\n",
    "        for i in range(len(data[\"event_ind\"])):\n",
    "            if data[\"event_ind\"][i]==ind:\n",
    "                ind_list.append(i)\n",
    "        event_pointer.append(ind_list)\n",
    "    return event_pointer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5858b110-ed80-4b94-b86d-191a7c676a42",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Vertex Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab7a522-018a-44d0-82d9-9593f43341ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_d2g_dt(fw,track_param,track):\n",
    "\n",
    "    dist = 999\n",
    "    dist_=[]\n",
    "    \n",
    "    #Projection to floor#\n",
    "    dt = fw[-1]-track_param[-1]\n",
    "    cental = track_point_propagation(track_param,dt)\n",
    "    \n",
    "    \n",
    "    #projection distance from IP #\n",
    "    track_new_loc = np.array( TK.floor_projection(0,track))\n",
    "    dr = np.linalg.norm(track_new_loc[:3])\n",
    "    \n",
    "    \n",
    "    # Total covariance is the track cov + hit cov\n",
    "    #track_new_pcov_inv = np.linalg.inv(track_cov_propagation(track_param, track_cov, dt, dt_err_add=1)+ np.diag(hit_uncertainty**2))\n",
    "    #chi2 = dr.T@track_new_pcov_inv@dr\n",
    "\n",
    "    if inBox(cental) != True:\n",
    "        return -999, dr \n",
    "    if inGap(cental):\n",
    "        return 0 , dr \n",
    "    elif inFW(fw) ==-1:\n",
    "        for i in range(2):\n",
    "            try:\n",
    "                xLim=ModuleXLims[inModuleX(cental[0])]\n",
    "                yLim=ModuleYLims[inModuleY(cental[1])]\n",
    "            except:\n",
    "                continue\n",
    "            if abs(cental[0]-xLim[i]) < dist :\n",
    "                dist = abs(cental[0]-xLim[i]) \n",
    "            if abs(cental[1]-yLim[i]) < dist :\n",
    "                dist = abs(cental[1]-yLim[i])  \n",
    "        dist_.append(dist)\n",
    "    elif -1 < inFW(fw) <= 2 :\n",
    "        for i in range(2):\n",
    "            try:\n",
    "                xLim=ModuleXLims[inModuleX(cental[0])]\n",
    "                zLim=ModuleZLims[inModuleZ(cental[2])]\n",
    "            except:\n",
    "                continue\n",
    "            if abs(cental[0]-xLim[i]) < dist :\n",
    "                dist = abs(cental[0]-xLim[i]) \n",
    "            if abs(cental[2]-zLim[i]) < dist :\n",
    "                dist = abs(cental[2]-zLim[i])  \n",
    "        dist_.append(dist)\n",
    "    if len(dist_)==0:\n",
    "        return -999, dr \n",
    "    if np.min(dist_) == 999:\n",
    "        return -999, dr \n",
    "    return np.min(dist_), dr\n",
    "\n",
    "\n",
    "\n",
    "def get_d2gap_dy(mid_points,track):\n",
    "    \n",
    "    \n",
    "    dist_=[]\n",
    "    dist=999\n",
    "    for mid in midpoints:\n",
    "        if inBox(cental) != True:\n",
    "            return -999, dr \n",
    "        if inGap(cental):\n",
    "            return 0 , dr \n",
    "        elif inFW(fw) ==-1:\n",
    "            for i in range(2):\n",
    "                try:\n",
    "                    xLim=ModuleXLims[inModuleX(cental[0])]\n",
    "                    yLim=ModuleYLims[inModuleY(cental[1])]\n",
    "                except:\n",
    "                    continue\n",
    "                if abs(cental[0]-xLim[i]) < dist :\n",
    "                    dist = abs(cental[0]-xLim[i]) \n",
    "                if abs(cental[1]-yLim[i]) < dist :\n",
    "                    dist = abs(cental[1]-yLim[i])  \n",
    "            dist_.append(dist)\n",
    "        elif -1 < inFW(fw) <= 2 :\n",
    "            for i in range(2):\n",
    "                try:\n",
    "                    xLim=ModuleXLims[inModuleX(cental[0])]\n",
    "                    zLim=ModuleZLims[inModuleZ(cental[2])]\n",
    "                except:\n",
    "                    continue\n",
    "                if abs(cental[0]-xLim[i]) < dist :\n",
    "                    dist = abs(cental[0]-xLim[i]) \n",
    "                if abs(cental[2]-zLim[i]) < dist :\n",
    "                    dist = abs(cental[2]-zLim[i])  \n",
    "            dist_.append(dist)\n",
    "    if len(dist_)==0:\n",
    "        return -999, dr \n",
    "    if np.min(dist_) == 999:\n",
    "        return -999, dr \n",
    "    return np.min(dist_), dr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeefe5d-5d8d-4492-8f7c-1fc3e3196c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# projcets the track Parameter & covariance using the time difference between the f/w digitized hits and the track#\n",
    "# then calculates the chi2 #\n",
    "def fwhits_to_chi2(hit,track_info):\n",
    "    # Hit uncertainty:\n",
    "    track_param =track_info[1]\n",
    "    track_cov  =track_info[0]\n",
    "    hit_uncertainty = get_hit_uncertainty(1, hit[1])\n",
    "\n",
    "    # Method 1: Calculate chi2 between F/W hits and track\n",
    "    dt = hit[-1]-track_param[-1]\n",
    "    track_new_loc = np.array(track_point_propagation(track_param,dt))\n",
    "    dr = track_new_loc[:3] - hit[:3]\n",
    "    # Total covariance is the track cov + hit cov\n",
    "    track_new_pcov_inv = np.linalg.inv(track_cov_propagation(track_param, track_cov, dt, dt_err_add=1)+ np.diag(hit_uncertainty**2))\n",
    "    chi2 = dr.T@track_new_pcov_inv@dr\n",
    "    return chi2 , np.linalg.norm(dr)\n",
    "\n",
    "\n",
    "# calculates the chi2 for the IP tracklet veto#\n",
    "def Track_to_IPtrack_chi2(hit, track_info):\n",
    "    track_param =track_info[1]\n",
    "    track_cov  =track_info[0]\n",
    "    hit_uncertainty = get_hit_uncertainty(1, hit[1])\n",
    "    \n",
    "    # defining the IP tracklet #\n",
    "    dr_IP = np.linalg.norm(hit[:3])\n",
    "    dt_IP = dr_IP/29.94\n",
    "    v0_IP = hit[:3]/dt_IP\n",
    "    # IP tracklet parameters and initial covariance #\n",
    "    track2_par = [hit[0], hit[1], hit[2], v0_IP[0], v0_IP[1], v0_IP[2], hit[3]]\n",
    "    track2_cov = IP_track_cov(hit, np.append(hit_uncertainty,1))\n",
    "    \n",
    "    # minimizing the sum of chi2 distances of both the tracklet and reconstructed track to find a common vertex#\n",
    "    fit1 = fit_vertex([track_param, track2_par], [track_cov, track2_cov], seedinedx=[0,1])\n",
    "    \n",
    "        # Calculate distance #\n",
    "    vertex_par=np.array(list(fit1.values))\n",
    "    vertex_par_detcoor = util.coord_cms2det(vertex_par[:3])\n",
    "    hit_detcoor = util.coord_cms2det(hit[:3])\n",
    "    track1_location_at_vertex = np.array(track_point_propagation(track_param,vertex_par[-1]-track_param[-1]))\n",
    "    track2_location_at_vertex = np.array(track_point_propagation(track2_par, vertex_par[-1]-track2_par[-1]))\n",
    "    dr_fit = np.linalg.norm(track1_location_at_vertex[:3] - track2_location_at_vertex[:3])\n",
    "    dist_to_IPtrack= dr_fit\n",
    "    dist2_to_IPtrack = find_distance_closestapproach(track_param, track2_par)\n",
    "    \n",
    "    # deflection \n",
    "    \n",
    "    momentum_measured = track_param[3:6]\n",
    "    momentum_measured_unit = momentum_measured/np.linalg.norm(momentum_measured)\n",
    "    \n",
    "    \n",
    "    return fit1.fval , dist_to_IPtrack , dist2_to_IPtrack \n",
    "\n",
    "# function to calculate the initial tracklet covariance #\n",
    "def IP_track_cov(hit, hit_unc):\n",
    "    \"\"\"\n",
    "    Construct the covariance of an \"IP track\" connecting from IP to a given hit\n",
    "    \n",
    "    Two points:\n",
    "    # IP: [0, 0, 0, t-dt], Hit: [x, y, z, t] \n",
    "    Track:\n",
    "    # Track: [x0, y0, z0, vx, vy, vx, t0] = [x, y, z, x/dt, y/dt, z/dt, t], in which dt = dr/c = sqrt(x^2+y^2+z^2)/c    \n",
    "    \n",
    "    \"\"\"\n",
    "    x,y,z,t = hit[:4]\n",
    "    c = 29.979\n",
    "    dt= np.linalg.norm(hit[:3])/c\n",
    "    dt3c2 = dt**3 * c**2\n",
    "    \n",
    "    # tracklet Jacobian #\n",
    "    # dependent on the difinition of the tracklet #\n",
    "    \n",
    "    jac = np.array([[1,    0,     0,    1/dt - x**2/dt3c2,         - x*y/dt3c2,         - x*z/dt3c2,  0],\n",
    "                   [0,    1,     0,         -  x*y/dt3c2,   1/dt - y**2/dt3c2,         - z*y/dt3c2,  0],\n",
    "                   [0,    0,     1,         -  x*z/dt3c2,         - z*y/dt3c2,   1/dt - z**2/dt3c2,  0],\n",
    "                   [0,    0,     0,                    0,                   0,                   0,  1]])\n",
    "\n",
    "    track_cov = jac.T @ np.diag(hit_unc**2) @ jac\n",
    "    return track_cov       \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Minute Minimization Step#\n",
    "class chi2_vertex:\n",
    "    def __init__(self, tracks, track_covs):\n",
    "        self.tracks=tracks\n",
    "        self.track_covs=track_covs\n",
    "        self.func_code = iminuit.util.make_func_code(['x0', 'y0', 'z0', 't0'])\n",
    "        self.errordef=1 # use least square\n",
    "    def __call__(self, x0, y0, z0, t0):\n",
    "        error=0\n",
    "        for itrack in range(len(self.tracks)):\n",
    "            error+= chi2_distance_to(self.tracks[itrack], self.track_covs[itrack], [x0, y0, z0], t0, point_t_err = 0)\n",
    "        return error        \n",
    "\n",
    "    \n",
    "def fit_vertex(track_pars, track_covs, seedinedx=[0,1], ncall=2000):\n",
    "    x0_init,y0_init, z0_init,t0_init = find_midpont_closestapproach(track_pars[seedinedx[0]], track_pars[seedinedx[1]])\n",
    "\n",
    "    m = Minuit(chi2_vertex(track_pars, track_covs),x0=x0_init, y0=y0_init, z0=z0_init, t0=t0_init)\n",
    "    limit_ext=2_00 # Extend the limit to beyond the decay volume\n",
    "    m.limits[\"x0\"]=(detector.Detector.BoxLimits[0][0]-limit_ext, detector.Detector.BoxLimits[0][1]+limit_ext)\n",
    "    m.limits[\"y0\"]=(detector.Detector.BoxLimits[1][0]-limit_ext, detector.Detector.BoxLimits[1][1]+limit_ext)\n",
    "    m.limits[\"z0\"]=(detector.Detector.BoxLimits[2][0]-limit_ext, detector.Detector.BoxLimits[2][1]+limit_ext)\n",
    "    m.limits[\"t0\"]=(0,1000)\n",
    "    m.errors[\"x0\"]=1\n",
    "    m.errors[\"y0\"]=1\n",
    "    m.errors[\"z0\"]=1\n",
    "    m.errors[\"t0\"]=1\n",
    "\n",
    "    m.migrad(ncall=ncall)  # run optimiser\n",
    "    # m.hesse()   # run covariance estimator\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c2570c-0210-49d7-bc72-b318c923bf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deflection(track_par,track):\n",
    "    x,y,z=track[:3] \n",
    "    utrack=np.linalg.norm([x[-1] - x[0], y[-1] - y[0], z[-1] - z[0]])\n",
    "    par_ip=track_par[:3]\n",
    "    upar=np.linalg.norm(track_par[:3])\n",
    "    angle=np.dot([x[-1] - x[0], y[-1] - y[0], z[-1] - z[0]],track_par[:3])/(utrack*upar)\n",
    "    return np.arccos(angle)/np.pi*180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8061f349-b68f-4015-9a13-88610b73fddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance to Gap intercept#\n",
    "\n",
    "def inFloor_Wall(point):\n",
    "    zval=point[2]\n",
    "    yval=point[1]\n",
    "    \n",
    "    if zval > 6895.1 and zval < 7000:\n",
    "        return True\n",
    "    \n",
    "    elif yval > 6548 and yval <= 6630 +scintillator_height_all and zval >= 7000 :\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "#Extends the reconstructed track until it intercepts either the floor/wall#\n",
    "def find_d2g_intercept(track_par,track):\n",
    "    if track_par[-1] > 400:\n",
    "        t= track_par[-1] - 399\n",
    "    else:\n",
    "        t = 50\n",
    "    point=track_par[:3]\n",
    "    found = False\n",
    "    while found == False:\n",
    "        t= t + 3\n",
    "        dt= - t\n",
    "        point = track_point_propagation(track_par,dt)\n",
    "        # if it intercepts with the floor, run track projection to floor midpoints#\n",
    "        if point[1] # if it intercepts with the floor, run track projection to floor midpoints#> 6548 and point[1] <= 6630:\n",
    "            return d2gap(track, \"floor\")\n",
    "        # if it intercepts with the wall, run track projection to wall midpoints#\n",
    "        elif point[2] > 6895.1 and point[2] < 7000:\n",
    "            return d2gap(track, \"wall\")\n",
    "\n",
    "# calculates the distance to gap by finding the projection point to either the modules of the floor/wall, then calculating the distance to the nearest edge.#    \n",
    "def d2gap(track,dirc):\n",
    "    dist_list=[]\n",
    "    dist = 99999\n",
    "    dist_=[]\n",
    "    central_point=[]    \n",
    "    if dirc==\"wall\":\n",
    "        for zval in wall_midpoint:\n",
    "            central_point.append(TK.wall_projection(zval,track))\n",
    "    elif  dirc==\"floor\":\n",
    "        for yval in floor_midpoint:\n",
    "            central_point.append(TK.floor_projection(yval,track))\n",
    "    for cental in (central_point):\n",
    "        if inBox(cental) != True:\n",
    "            dist_.append(999)\n",
    "    \n",
    "        elif inGap(cental):\n",
    "            return  0\n",
    "        elif dirc==\"wall\":\n",
    "            for i in range(2):\n",
    "                try:\n",
    "                    xLim=ModuleXLims[inModuleX(cental[0])]\n",
    "                    yLim=ModuleYLims[inModuleY(cental[1])]\n",
    "                except:\n",
    "                    continue\n",
    "                if abs(cental[0]-xLim[i]) < dist :\n",
    "                    dist = abs(cental[0]-xLim[i]) \n",
    "                if abs(cental[1]-yLim[i]) < dist :\n",
    "                    dist = abs(cental[1]-yLim[i])  \n",
    "            dist_.append(dist)\n",
    "        elif dirc==\"floor\":\n",
    "            for i in range(2):\n",
    "                try:\n",
    "                    xLim=ModuleXLims[inModuleX(cental[0])]\n",
    "                    zLim=ModuleZLims[inModuleZ(cental[2])]\n",
    "                except:\n",
    "                    continue\n",
    "                if abs(cental[0]-xLim[i]) < dist :\n",
    "                    dist = abs(cental[0]-xLim[i]) \n",
    "                if abs(cental[2]-zLim[i]) < dist :\n",
    "                    dist = abs(cental[2]-zLim[i])  \n",
    "            dist_.append(dist)\n",
    "        if len(dist_)==0:\n",
    "            continue\n",
    "        dist_list.append(min(dist_))\n",
    "    if len(dist_list)==0:\n",
    "        return -999\n",
    "    if np.min(dist_list) == 999:\n",
    "        return -999\n",
    "    return np.min(dist_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baca4b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c081db85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_res_pull(data, figs=None, make_legend=False, plot_gauss1=True, label=\"\", figsize=(10,3.5)):\n",
    "    axlabels=[\"$x_0$ [cm]\",\"$y_0$ [cm]\", \"$t_0$ [ns]\", \"$v_x$ [cm/ns]\", \"$v_y$ [cm/ns]\", \"$v_z$ [cm/ns]\"]\n",
    "    ranges=np.array([[-15,15],[-15,15],[-4,4],[-2,2], [-2,2], [-6,6]])\n",
    "\n",
    "    mask_recon_success=data[\"mask_recon_success\"]\n",
    "    recon     =np.array(data[\"recon\"])[mask_recon_success]\n",
    "    recon_unc =np.array(data[\"recon_error\"])[mask_recon_success]\n",
    "    truth     =np.array(data[\"truth\"])[mask_recon_success]\n",
    "\n",
    "    \n",
    "    if figs is None:\n",
    "        figs = []\n",
    "        for i in range(6):\n",
    "            fig,axs=plt.subplots(1,2,figsize=figsize)\n",
    "            figs.append(fig)\n",
    "\n",
    "    for ipar in range(6):\n",
    "        ipar_cms = INDS_PAR[ipar]\n",
    "        residual=(recon-truth)[:,ipar_cms]\n",
    "        pull=util.pull(residual,0,recon_unc[:,ipar_cms])\n",
    "\n",
    "        # plotrange=[-2*np.std(residual_kf), 2*np.std(residual_kf)]\n",
    "        plotrange=ranges[ipar]\n",
    "\n",
    "        # fig,axs=plt.subplots(1,2,figsize=(10,4))\n",
    "        figure(figs[ipar])\n",
    "        axs=figs[ipar].axes\n",
    "        plt.sca(axs[0])\n",
    "        n,ibins,p = hist(residual,range=plotrange,histtype=\"step\",label=label,bins=100);\n",
    "        yscale(\"log\")\n",
    "        ymin, ymax = gca().get_ylim()\n",
    "        ylim(bottom=1, top = max([max(n)*2,ymax]))        \n",
    "        xlabel(\"Reco-truth, \"+axlabels[ipar])\n",
    "        ylabel(\"[counts/bin]\")\n",
    "\n",
    "        plt.sca(axs[1])\n",
    "        n,ibins,p = hist(pull,range=[-5,5],histtype=\"step\",label=label,bins=100);\n",
    "\n",
    "        bincenters=0.5*(ibins[1:]+ibins[:-1])\n",
    "        y = util.Utils.Gauss(bincenters, max(n),0,1)\n",
    "        if plot_gauss1:\n",
    "            plt.plot(bincenters,y,color=\"r\",label=r\"Gauss, $\\sigma$=1\",linestyle=\":\")\n",
    "            \n",
    "        yscale(\"log\")\n",
    "        ymin, ymax = gca().get_ylim()\n",
    "        ylim(bottom=1, top = max([max(n)*2,ymax]))\n",
    "        xlabel(r\"$\\frac{Reco-truth}{Unc_{reco}}$, \"+axlabels[ipar].split(\" \")[0]+\" [$\\sigma$]\")\n",
    "        \n",
    "        if make_legend:\n",
    "            plt.legend(loc=(1.01,0),fontsize=11)\n",
    "    \n",
    "    return figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23404aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_eff(res, PDG_TRUTH = 13):\n",
    "    recon     =np.array(res[\"recon\"])\n",
    "    recon_unc =np.array(res[\"recon_error\"])\n",
    "    truth     =np.array(res[\"truth\"])\n",
    "    \n",
    "    \n",
    "    mask_recon_success=res[\"mask_recon_success\"]\n",
    "    mask_recon_able = (res[\"truth_nlayer\"]>=5)& (res[\"truth_nlayer\"]<=9) # layer 2 is the bottom layer, 9 is the top\n",
    "    \n",
    "    mask_identified= np.zeros(len(res[\"recon\"]),dtype=bool)\n",
    "    for i in range(len(mask_identified)):\n",
    "        n_truth_id = sum(np.array(res[\"par_km_pdgids\"][i])==PDG_TRUTH)\n",
    "        n_false_id = sum(np.array(res[\"par_km_pdgids\"][i])!=PDG_TRUTH)\n",
    "        track_purity = n_truth_id/(n_truth_id+n_false_id)\n",
    "        if n_truth_id>=4 and n_false_id==0:\n",
    "            mask_identified[i]=True\n",
    "    \n",
    "    n_events = len(mask_recon_success)\n",
    "    n_success = np.sum(mask_recon_success)\n",
    "    \n",
    "        \n",
    "    # Make a fixed range cut for tight and looser track\n",
    "    diffx = recon[:,2]-truth[:,2]\n",
    "    diffy = recon[:,0]-truth[:,0]\n",
    "    diffvx = recon[:,6]-truth[:,6]\n",
    "    diffvy = recon[:,4]-truth[:,4] \n",
    "    mask_TIGHT  = (np.abs(diffx)<5) & (np.abs(diffy)<5) & (np.abs(diffvx)<0.5) & (np.abs(diffvy)<0.5)\n",
    "    mask_LOOSER = (np.abs(diffx)<10) & (np.abs(diffy)<10) & (np.abs(diffvx)<1) & (np.abs(diffvy)<1)\n",
    "            \n",
    "            \n",
    "    eff_raw=util.Utils.flatten1d(list(rt.BayesDivide([sum(mask_recon_success)],[len(mask_recon_success)])))\n",
    "    eff_abs_tight=util.Utils.flatten1d(list(rt.BayesDivide([sum(mask_TIGHT&mask_recon_success)],[len(mask_recon_success)])))\n",
    "    eff_abs_loose=util.Utils.flatten1d(list(rt.BayesDivide([sum(mask_LOOSER&mask_recon_success)],[len(mask_recon_success)])))\n",
    "\n",
    "    eff_reconstructible = util.Utils.flatten1d(list(rt.BayesDivide([sum(mask_recon_able)],[len(mask_recon_success)])))\n",
    "    eff_identified=util.Utils.flatten1d(list(rt.BayesDivide([sum(mask_identified&mask_recon_able)],[sum(mask_recon_able)])))\n",
    "    eff_resolution =util.Utils.flatten1d(list(rt.BayesDivide([sum(mask_LOOSER&mask_identified&mask_recon_able)],[sum(mask_identified&mask_recon_able)])))\n",
    "    \n",
    "    if len(eff_resolution)==0:\n",
    "        eff_resolution = [0,0,0]\n",
    "    \n",
    "    return eff_raw, eff_abs_tight, eff_abs_loose, eff_reconstructible,  eff_identified, eff_resolution\n",
    "\n",
    "\n",
    "def calc_resolution(res):\n",
    "    recon     =np.array(res[\"recon\"])\n",
    "    recon_unc =np.array(res[\"recon_error\"])\n",
    "    truth     =np.array(res[\"truth\"])\n",
    "    \n",
    "    \n",
    "    mask_recon_success=res[\"mask_recon_success\"]\n",
    "    ranges=np.array([[-15,15],[-15,15],[-4,4],[-2,2], [-2,2], [-6,6]])\n",
    "    ind = INDS_PAR\n",
    "    \n",
    "    sigmas = []\n",
    "    sigmas_unc = []\n",
    "    fwhms = []\n",
    "    for i in range(6):\n",
    "        diff = recon[:,ind[i]]-truth[:,ind[i]]\n",
    "        n,ibins= np.histogram(diff,bins=100,range=ranges[i]);\n",
    "        \n",
    "        \n",
    "        bincenters=0.5*(ibins[1:]+ibins[:-1])\n",
    "        yerr=np.sqrt(n);yerr[yerr==0]=1\n",
    "        \n",
    "        popt,pcov = rt.fit_tg(bincenters,n,yerr=yerr,function=\"gaus\")\n",
    "        perr = np.sqrt(np.diag(pcov))\n",
    "        \n",
    "        fw = util.Utils.fwhm(bincenters, n)\n",
    "        fwhm = fw[1]-fw[0]\n",
    "        \n",
    "        sigmas.append(popt[2])\n",
    "        sigmas_unc.append(perr[2])\n",
    "        fwhms.append(fwhm)\n",
    "        \n",
    "    return sigmas,sigmas_unc,fwhms\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1c02e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_km_alltracks(filename, results_fit = None, tree_name=\"integral_tree\", truth_pids = [13,13], nevents=-1):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ---\n",
    "    nevents: \n",
    "      -1: all events\n",
    "      (start, stop) from start to stop\n",
    "    \"\"\"\n",
    "    \n",
    "    if results_fit is None:\n",
    "        results_fit={}\n",
    "\n",
    "        \n",
    "    results_fit[\"Entry\"]=[]               # ROOT event entry number\n",
    "    results_fit[\"ndigi\"]=[]               # Total number of digitized hits\n",
    "    results_fit[\"Digi_track_id\"]=[]\n",
    "    results_fit[\"mask_recon_success_track\"]=[]    # Boolean mask \n",
    "    results_fit[\"mask_recon_success_vertex\"]=[]   # Boolean mask \n",
    "    results_fit[\"mask_reconstructible_vertex\"]=[]   # Boolean mask, if an event has two tracks with 4+ hits. The track is required to be from the direct input\n",
    "    results_fit[\"mask_reconstructible2_vertex\"]=[]   # Boolean mask, if an event has two tracks with 4+ hits. The track can be from any particle.  \n",
    "\n",
    "    \n",
    "    results_fit[\"tracks_truth\"]=[]\n",
    "    results_fit[\"tracks_truth_n\"]=[]\n",
    "    results_fit[\"tracks_truth_nlayer\"]=[]\n",
    "    results_fit[\"tracks_truth_pdgids\"]=[]\n",
    "    \n",
    "    results_fit[\"tracks_recon\"]=[]\n",
    "    results_fit[\"tracks_recon_n\"]=[]\n",
    "    results_fit[\"tracks_recon_error\"]=[]          # KF parameter uncertainty. Already taken sqrt()\n",
    "    results_fit[\"tracks_ndigi\"]=[]          #  number of digitized hits in the track\n",
    "    results_fit[\"tracks_ndigi_false\"]=[]    #  number of digitized hits in the track that are not from the truth\n",
    "    results_fit[\"tracks_purity\"]=[]         # List of PDG id of hits in this track \n",
    "    results_fit[\"tracks_pdgids\"]=[]         # List of PDG id of hits in this track \n",
    "    results_fit[\"tracks_chi2\"]=[]           # KF fit chi2\n",
    "    \n",
    "    results_fit[\"vertices_truth\"]=[]\n",
    "    results_fit[\"vertices_ntrack\"]=[]\n",
    "    results_fit[\"vertices_ntrack_truth\"]=[]\n",
    "    results_fit[\"vertices_recon\"]=[]\n",
    "    results_fit[\"vertices_recon_n\"]=[]\n",
    "    results_fit[\"vertices_recon_error\"]=[]\n",
    "    results_fit[\"vertices_recon_cov\"]=[]\n",
    "    results_fit[\"vertices_chi2\"]=[]\n",
    "    \n",
    "\n",
    "\n",
    "    ev = event.Event(filename, 0, tree_name=tree_name)\n",
    "    Tree=ev.Tree\n",
    "    nevents_total = int(ev.Tree.GetEntries())\n",
    "    cut=cutflow.sample_space(\"\")\n",
    "    \n",
    "    if nevents==-1:\n",
    "        nevents = [0, nevents_total]\n",
    "    elif type(nevents) is int:\n",
    "        if nevents_total<nevents:\n",
    "            print(f\"Requested events exceed total {nevents_total}\")\n",
    "        nevents = [0, min(nevents,nevents_total)]\n",
    "    else:\n",
    "        if nevents_total<nevents[1]:\n",
    "            print(f\"Requested events exceed total {nevents_total}\")        \n",
    "        nevents = [nevents[0], min(nevents[1],nevents_total)]\n",
    "\n",
    "    for i_event in tqdm(range(nevents[0], nevents[1])):\n",
    "        ev.EventNumber=i_event\n",
    "        ev.Tree.GetEntry(i_event)\n",
    "        ev.ExtractTruthPhysics_list()\n",
    "        \n",
    "        par_km_ndigi = ev.Tree.Digi_x.size()\n",
    "        \n",
    "        results_fit[\"Entry\"].append(i_event)\n",
    "        results_fit[\"ndigi\"].append(par_km_ndigi)\n",
    "        results_fit[\"Digi_track_id\"].append(util.c2list(ev.Tree.Digi_track_id))\n",
    "        ids=np.array(results_fit[\"Digi_track_id\"][-1])\n",
    "        ys = np.array(util.c2list(ev.Tree.Digi_y))\n",
    "        n_reconstructible=0\n",
    "        n_reconstructible2=0\n",
    "        for g4id in range(0,200):\n",
    "            if len(np.unique(ys[ids==g4id]))>=4:\n",
    "                n_reconstructible+=1\n",
    "        for g4id in np.unique(ids):\n",
    "            if len(np.unique(ys[ids==g4id]))>=4:\n",
    "                n_reconstructible2+=1                \n",
    "        results_fit[\"vertices_ntrack_truth\"].append(n_reconstructible)\n",
    "        if n_reconstructible>=2:\n",
    "            results_fit[\"mask_reconstructible_vertex\"].append(True)\n",
    "        else:\n",
    "            results_fit[\"mask_reconstructible_vertex\"].append(False)   \n",
    "        if n_reconstructible2>=2:\n",
    "            results_fit[\"mask_reconstructible2_vertex\"].append(True)\n",
    "        else:\n",
    "            results_fit[\"mask_reconstructible2_vertex\"].append(False)               \n",
    "\n",
    "        # Get truth (speed need to be calculated by hand)\n",
    "        try:\n",
    "            # Truth position and speed\n",
    "            TruthTracks = []\n",
    "            Truths = []\n",
    "            Truth_nlayer = []\n",
    "            Truth_pdgids = []\n",
    "            for track in ev.truthTrackList_list:\n",
    "                if track[4][0] in truth_pids:\n",
    "                    TruthTracks.append(track)\n",
    "                    dt=track[3][1]-track[3][0]\n",
    "                    vx=(track[0][1]-track[0][0])/dt\n",
    "                    vy=(track[1][1]-track[1][0])/dt\n",
    "                    vz=(track[2][1]-track[2][0])/dt\n",
    "                    truth = [track[0][0], track[1][0], track[2][0], track[3][0],vx,vy,vz]  \n",
    "                    Truths.append(truth)\n",
    "                    Truth_nlayer.append(np.abs(cut.in_layer(track[1][-1])-cut.in_layer(track[1][0])))\n",
    "                    Truth_pdgids.append(track[4][0])\n",
    "            \n",
    "            n_truthtracks=len(TruthTracks)\n",
    "            results_fit[\"tracks_truth\"].append(Truths)  \n",
    "            results_fit[\"tracks_truth_n\"].append(n_truthtracks)  \n",
    "            results_fit[\"tracks_truth_nlayer\"].append(Truth_nlayer)  \n",
    "            \n",
    "        except:\n",
    "            n_truthtracks=0\n",
    "            results_fit[\"tracks_truth\"].append([[-9999]])\n",
    "            results_fit[\"tracks_truth_n\"].append(n_truthtracks)  \n",
    "            results_fit[\"tracks_truth_nlayer\"].append([[-9999]])\n",
    "                  \n",
    "        \n",
    "        # If there is reconstruction:\n",
    "        if len(ev.Tree.Track_k_m_z0)==0:\n",
    "            tracks_recon = [[-9990, -9990, -9990, -9990, -9990, -9990, -9990]]\n",
    "            tracks_recon_n = 0\n",
    "            tracks_recon_error = [[-9990, -9990, -9990, -9990, -9990, -9990, -9990]]\n",
    "            tracks_chi2 = [0]\n",
    "            \n",
    "            tracks_ndigi = [0]\n",
    "            tracks_ndigi_false = [0]\n",
    "            tracks_purity = [-999]\n",
    "            tracks_pdgids = [0]\n",
    "            results_fit[\"mask_recon_success_track\"].append(False)\n",
    "            \n",
    "        else:\n",
    "            tracks_recon = []\n",
    "            tracks_recon_n = Tree.Track_k_m_z0.size()\n",
    "            tracks_recon_error = []\n",
    "            tracks_chi2 = []\n",
    "            tracks_ndigi = []\n",
    "            tracks_ndigi_false = []\n",
    "            tracks_purity = []\n",
    "            tracks_pdgids = []            \n",
    "            \n",
    "            \n",
    "            # Select the reconstruction that is closest to truth\n",
    "            track_digi_hit_inds = util.unzip(Tree.Track_k_m_hitIndices)\n",
    "            track_truth_ids = util.unzip(Tree.Track_k_m_ids)\n",
    "            track_digi_hit_len = np.array([len(i) for i in track_digi_hit_inds])\n",
    "            if tracks_recon_n<n_truthtracks:\n",
    "                results_fit[\"mask_recon_success_track\"].append(False)\n",
    "            else:\n",
    "                results_fit[\"mask_recon_success_track\"].append(True)                \n",
    "                \n",
    "            for i_track in range(len(TruthTracks)):\n",
    "                truth = Truths[i_track]\n",
    "\n",
    "                track_chi2s = []\n",
    "                if len(track_digi_hit_inds)>1:\n",
    "                    for track_ind in range(len(track_digi_hit_inds)):\n",
    "                        recon_i = [Tree.Track_k_m_x0.at(track_ind), Tree.Track_k_m_y0.at(track_ind), Tree.Track_k_m_z0.at(track_ind), Tree.Track_k_m_t0.at(track_ind),Tree.Track_k_m_velX.at(track_ind), Tree.Track_k_m_velY.at(track_ind), Tree.Track_k_m_velZ.at(track_ind)]\n",
    "                        recon_i_unc = [Tree.Track_k_m_ErrorX0.at(track_ind), Tree.Track_k_m_ErrorY0.at(track_ind), Tree.Track_k_m_ErrorZ0.at(track_ind), Tree.Track_k_m_ErrorT0.at(track_ind),Tree.Track_k_m_ErrorVx.at(track_ind), Tree.Track_k_m_ErrorVy.at(track_ind), Tree.Track_k_m_ErrorVz.at(track_ind)]\n",
    "                        chi2 = util.chi2_calc(recon_i,truth,recon_i_unc)\n",
    "                        track_chi2s.append(chi2)\n",
    "                    track_ind = int(np.argmin(track_chi2s))\n",
    "                else:\n",
    "                    track_ind=0\n",
    "\n",
    "                tracks_recon.append([ev.Tree.Track_k_m_x0.at(track_ind), ev.Tree.Track_k_m_y0.at(track_ind), ev.Tree.Track_k_m_z0.at(track_ind), ev.Tree.Track_k_m_t0.at(track_ind), ev.Tree.Track_k_m_velX.at(track_ind), ev.Tree.Track_k_m_velY.at(track_ind), ev.Tree.Track_k_m_velZ.at(track_ind)])\n",
    "                tracks_recon_error.append([ev.Tree.Track_k_m_ErrorX0.at(track_ind), ev.Tree.Track_k_m_ErrorY0.at(track_ind), ev.Tree.Track_k_m_ErrorZ0.at(track_ind), ev.Tree.Track_k_m_ErrorT0.at(track_ind), ev.Tree.Track_k_m_ErrorVx.at(track_ind), ev.Tree.Track_k_m_ErrorVy.at(track_ind), ev.Tree.Track_k_m_ErrorVz.at(track_ind)])\n",
    "                tracks_chi2.append(ev.Tree.Track_k_m_smooth_chi_sum.at(track_ind))\n",
    "                \n",
    "                track_hits_inds=track_digi_hit_inds[track_ind]\n",
    "                truth_pid = TruthTracks[i_track][4][0]\n",
    "                truth_track_id = TruthTracks[i_track][6][0]\n",
    "                kalmantrack_truthtrack_ids = track_truth_ids[track_ind]\n",
    "                \n",
    "                tracks_pdgids.append([ev.Tree.Digi_pdg_id.at(i) for i in track_hits_inds])\n",
    "                tracks_ndigi.append(len(track_hits_inds))\n",
    "                tracks_ndigi_false.append(sum(np.array(kalmantrack_truthtrack_ids)!=truth_track_id))\n",
    "                tracks_purity.append(1-tracks_ndigi_false[-1]/tracks_ndigi[-1])\n",
    "                \n",
    "        # Vertex========================================================\n",
    "        if len(ev.Tree.Vertex_k_m_x)==0:\n",
    "            vertex_recon = [[0]]\n",
    "            vertex_recon_n=0\n",
    "            vertex_recon_error=[[0]]\n",
    "            vertices_chi2=[[0]]\n",
    "            vertex_recon_cov=[]\n",
    "            results_fit[\"mask_recon_success_vertex\"].append(False) \n",
    "        else:\n",
    "            results_fit[\"mask_recon_success_vertex\"].append(True) \n",
    "            vertex_recon=[]\n",
    "            vertex_recon_n = Tree.Vertex_k_m_x.size()\n",
    "            vertex_recon_error=[]\n",
    "            vertex_recon_cov=[]\n",
    "            vertices_chi2=[]\n",
    "            for iv in range(vertex_recon_n):\n",
    "                v=[Tree.Vertex_k_m_x.at(iv),Tree.Vertex_k_m_y.at(iv),Tree.Vertex_k_m_z.at(iv),Tree.Vertex_k_m_t.at(iv)]\n",
    "                vertex_recon.append(v)\n",
    "                verr=[Tree.Vertex_k_m_ErrorX.at(iv),Tree.Vertex_k_m_ErrorY.at(iv),Tree.Vertex_k_m_ErrorZ.at(iv),Tree.Vertex_k_m_ErrorT.at(iv)]\n",
    "                vertex_recon_error.append(verr)  \n",
    "                vcov=[[Tree.Vertex_k_m_ErrorX.at(iv)**2, Tree.Vertex_k_m_cov_x_y.at(iv), Tree.Vertex_k_m_cov_x_z.at(iv), Tree.Vertex_k_m_cov_t_x.at(iv)],\n",
    "                      [Tree.Vertex_k_m_cov_x_y.at(iv),   Tree.Vertex_k_m_ErrorY.at(iv)**2, Tree.Vertex_k_m_cov_y_z.at(iv), Tree.Vertex_k_m_cov_t_y.at(iv)],\n",
    "                      [Tree.Vertex_k_m_cov_x_z.at(iv),   Tree.Vertex_k_m_cov_y_z.at(iv), Tree.Vertex_k_m_ErrorZ.at(iv)**2, Tree.Vertex_k_m_cov_t_z.at(iv)],\n",
    "                      [Tree.Vertex_k_m_cov_t_x.at(iv),   Tree.Vertex_k_m_cov_t_y.at(iv), Tree.Vertex_k_m_cov_t_z.at(iv), Tree.Vertex_k_m_ErrorT.at(iv)**2]]\n",
    "                vertex_recon_cov.append(vcov)\n",
    "                vertices_chi2.append(Tree.Vertex_k_m_chi2.at(iv))\n",
    "                \n",
    "        vertex_truth_cms = [Tree.GenParticle_y.at(1)*0.1, -Tree.GenParticle_z.at(1)*0.1 + 8547, Tree.GenParticle_x.at(1)*0.1]\n",
    "        vertex_track_inds = util.unzip(Tree.Vertex_k_m_trackIndices)\n",
    "        vertex_ntrack = [len(ii) for ii in vertex_track_inds]\n",
    "        \n",
    "        \n",
    "        results_fit[\"tracks_recon\"].append(tracks_recon)\n",
    "        results_fit[\"tracks_recon_n\"].append(tracks_recon_n)\n",
    "        results_fit[\"tracks_recon_error\"].append(np.sqrt(tracks_recon_error))\n",
    "        results_fit[\"tracks_chi2\"].append(tracks_chi2)\n",
    "        results_fit[\"tracks_ndigi\"].append(tracks_ndigi)\n",
    "        results_fit[\"tracks_ndigi_false\"].append(tracks_ndigi_false)\n",
    "        results_fit[\"tracks_purity\"].append(tracks_purity)\n",
    "        results_fit[\"tracks_pdgids\"].append(tracks_pdgids)\n",
    "        \n",
    "        results_fit[\"vertices_truth\"].append(vertex_truth_cms)\n",
    "        results_fit[\"vertices_ntrack\"].append(vertex_ntrack)\n",
    "        results_fit[\"vertices_recon\"].append(vertex_recon)\n",
    "        results_fit[\"vertices_recon_n\"].append(vertex_recon_n)\n",
    "        results_fit[\"vertices_recon_error\"].append(vertex_recon_error)\n",
    "        results_fit[\"vertices_recon_cov\"].append(vertex_recon_cov)\n",
    "        results_fit[\"vertices_chi2\"].append(vertices_chi2)\n",
    "        \n",
    "        \n",
    "    for key in [\"tracks_truth_n\",\"tracks_recon_n\",\"mask_recon_success_track\", \"mask_recon_success_vertex\",\"vertices_recon_n\", \"vertices_ntrack_truth\"]:\n",
    "        results_fit[key]=np.array(results_fit[key])\n",
    "        \n",
    "        \n",
    "    return results_fit\n",
    "\n",
    "\n",
    "def closest_approach_midpoint(tr1, tr2):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    ---\n",
    "    tr1,tr2:\n",
    "        lists of track paramters [x0, y0, x0, vx, vy, vz, t0]\n",
    "        \n",
    "    return:\n",
    "    ---\n",
    "    midpoint([x,y,z]), midpoint_time, distance\n",
    "    \"\"\"\n",
    "\n",
    "    rel_v = tr2[3:6] - tr1[3:6];\n",
    "    rel_v2 = np.dot(rel_v, rel_v) \n",
    "\n",
    "    displacement = tr2[:3] - tr1[:3]; # position difference\n",
    "    t_ca = -(  np.dot(displacement, rel_v) - np.dot((tr2[3:6]*tr2[6] - tr1[3:6]*tr1[6]), rel_v)  )/rel_v2;\n",
    "    \n",
    "    displacement = tr1[:3] - tr2[:3]; # position difference\n",
    "    t_ca = (  np.dot(displacement, rel_v) + np.dot((tr2[3:6]*tr2[6] - tr1[3:6]*tr1[6]), rel_v)  )/rel_v2;    \n",
    "    \n",
    "\n",
    "    pos1 = tr1[:3] + tr1[3:6]*(t_ca - tr1[6]);\n",
    "    pos2 = tr2[:3] + tr2[3:6]*(t_ca - tr2[6]);\n",
    "    \n",
    "    line_distance = np.linalg.norm((pos1- pos2))\n",
    "\n",
    "    return (pos1 + pos2)*(0.5), t_ca, line_distance\n",
    "\n",
    "\n",
    "def find_midpont_closestapproach(track1_par, track2_par):\n",
    "    # Find the midpoint of two tracks with \"closeset approach\"\n",
    "    # Test: find_midpont_closestapproach([0,0,0, 0,1,0 ,0], [0,1,-1, 0,0,1, 0])\n",
    "    # These two lines should intersect at [0,1,0,1]\n",
    "    r1 = np.array(track1_par[:3]); v1 = np.array(track1_par[3:6]); t1 = track1_par[-1]\n",
    "    r2 = np.array(track2_par[:3]); v2 = np.array(track2_par[3:6]); t2 = track2_par[-1]\n",
    "    rel_v = v2-v1\n",
    "    rel_vsq = np.dot(rel_v, rel_v)\n",
    "    displacement = r1-r2\n",
    "    \n",
    "    t_ca = ((displacement@rel_v.T) - ( v1*t1 - v2*t2)@rel_v.T)  /rel_vsq;\n",
    "    pos1 = r1 + v1*(t_ca - t1);\n",
    "    pos2 = r2 + v2*(t_ca - t2);\n",
    "    \n",
    "    mid =  (pos1 + pos2)*0.5;\n",
    "    return [*mid, t_ca]\n",
    "\n",
    "def find_distance_closestapproach(track1_par, track2_par):\n",
    "    r1 = np.array(track1_par[:3]); v1 = np.array(track1_par[3:6]); t1 = track1_par[-1]\n",
    "    r2 = np.array(track2_par[:3]); v2 = np.array(track2_par[3:6]); t2 = track2_par[-1]\n",
    "    rel_v = v2-v1\n",
    "    rel_vsq = np.dot(rel_v, rel_v)\n",
    "    displacement = r1-r2\n",
    "    \n",
    "    t_ca = ((displacement@rel_v.T) - ( v1*t1 - v2*t2)@rel_v.T)  /rel_vsq;\n",
    "    pos1 = r1 + v1*(t_ca - t1);\n",
    "    pos2 = r2 + v2*(t_ca - t2);\n",
    "    \n",
    "    dist =  np.linalg.norm(pos1-pos2);\n",
    "    return dist\n",
    "\n",
    "\n",
    "def line_dist(tr1,tr2,t_ca):\n",
    "    pos1 = tr1[:3] + tr1[3:6]*(t_ca - tr1[6]);\n",
    "    pos2 = tr2[:3] + tr2[3:6]*(t_ca - tr2[6]);  \n",
    "    displacement = pos1-pos2\n",
    "    \n",
    "    return np.dot(displacement,displacement)\n",
    "\n",
    "\n",
    "def get_track_cov(Tree, i):\n",
    "    i=int(i)\n",
    "    return np.array([[Tree.Track_k_m_ErrorX0.at(i), 0                           , Tree.Track_k_m_cov_x_z.at(i), Tree.Track_k_m_cov_x_vx.at(i), Tree.Track_k_m_cov_x_vy.at(i), Tree.Track_k_m_cov_x_vz.at(i), Tree.Track_k_m_cov_x_t.at(i)],\n",
    "                    [0                            , Tree.Track_k_m_ErrorY0.at(i), 0                           , 0,0,0,0],\n",
    "                    [Tree.Track_k_m_cov_x_z.at(i), 0                            , Tree.Track_k_m_ErrorZ0.at(i), Tree.Track_k_m_cov_z_vx.at(i), Tree.Track_k_m_cov_z_vy.at(i), Tree.Track_k_m_cov_z_vz.at(i), Tree.Track_k_m_cov_t_z.at(i)],\n",
    "                    [Tree.Track_k_m_cov_x_vx.at(i), 0                            , Tree.Track_k_m_cov_z_vx.at(i), Tree.Track_k_m_ErrorVx.at(i), Tree.Track_k_m_cov_vx_vy.at(i), Tree.Track_k_m_cov_vx_vz.at(i), Tree.Track_k_m_cov_t_vx.at(i)],\n",
    "                    [Tree.Track_k_m_cov_x_vy.at(i), 0                            , Tree.Track_k_m_cov_z_vy.at(i), Tree.Track_k_m_cov_vx_vy.at(i), Tree.Track_k_m_ErrorVy.at(i), Tree.Track_k_m_cov_vy_vz.at(i), Tree.Track_k_m_cov_t_vy.at(i)],\n",
    "                    [Tree.Track_k_m_cov_x_vz.at(i), 0                            , Tree.Track_k_m_cov_z_vz.at(i), Tree.Track_k_m_cov_vx_vz.at(i), Tree.Track_k_m_cov_vy_vz.at(i), Tree.Track_k_m_ErrorVz.at(i), Tree.Track_k_m_cov_t_vz.at(i)],\n",
    "                    [Tree.Track_k_m_cov_x_t.at(i), 0                            , Tree.Track_k_m_cov_t_z.at(i), Tree.Track_k_m_cov_t_vx.at(i), Tree.Track_k_m_cov_t_vy.at(i), Tree.Track_k_m_cov_t_vz.at(i), Tree.Track_k_m_ErrorT0.at(i)],])\n",
    "\n",
    "def get_track_param(Tree,track_ind):\n",
    "    track_ind=int(track_ind)\n",
    "    return np.array([Tree.Track_k_m_x0.at(track_ind), Tree.Track_k_m_y0.at(track_ind), Tree.Track_k_m_z0.at(track_ind),Tree.Track_k_m_velX.at(track_ind), Tree.Track_k_m_velY.at(track_ind), Tree.Track_k_m_velZ.at(track_ind), Tree.Track_k_m_t0.at(track_ind)])\n",
    "def get_track(Tree,track_ind):\n",
    "    track=[]\n",
    "    track_ind=int(track_ind)\n",
    "    track_digi_hit_inds = util.unzip(Tree.Track_k_m_hitIndices)\n",
    "    x_s = util.unzip(Tree.x_estimates_m)\n",
    "    y_s = util.unzip(Tree.y_estimates_m)\n",
    "    z_s = util.unzip(Tree.z_estimates_m)\n",
    "    for n in range(len(track_digi_hit_inds)):\n",
    "        x,y,z,t=[],[],[],[]\n",
    "\n",
    "    #fill recon information\n",
    "        track.append([x_s[int(n)], y_s[int(n)], z_s[int(n)]])\n",
    "    return [x_s[int(n)], y_s[int(n)], z_s[int(n)]]\n",
    "\n",
    "def get_track_param_truth_p(Tree,track_ind):\n",
    "    track_ind=int(track_ind)\n",
    "    g4trackind = np.array(util.c2list(Tree.Hit_G4TrackId))\n",
    "    hit_index = int(np.argmax(g4trackind==track_ind))\n",
    "    \n",
    "    return np.array([Tree.Hit_x.at(hit_index), Tree.Hit_y.at(hit_index), Tree.Hit_z.at(hit_index),Tree.Hit_particlePx.at(hit_index), Tree.Hit_particlePy.at(hit_index), Tree.Hit_particlePz.at(hit_index), Tree.Hit_time.at(hit_index)])\n",
    "\n",
    "def get_track_param_truth_v(Tree,track_ind):\n",
    "    track_ind=int(track_ind)\n",
    "    g4trackind = np.array(util.c2list(Tree.Hit_G4TrackId))\n",
    "    hit_index = int(np.argmax(g4trackind==track_ind))\n",
    "    dx = Tree.Hit_x.at(hit_index+1)-Tree.Hit_x.at(hit_index)\n",
    "    dy = Tree.Hit_y.at(hit_index+1)-Tree.Hit_y.at(hit_index)\n",
    "    dz = Tree.Hit_z.at(hit_index+1)-Tree.Hit_z.at(hit_index)\n",
    "    dt = Tree.Hit_time.at(hit_index+1)-Tree.Hit_time.at(hit_index)\n",
    "    \n",
    "    return np.array([Tree.Hit_x.at(hit_index), Tree.Hit_y.at(hit_index), Tree.Hit_z.at(hit_index), dx/dt, dy/dt, dz/dt, Tree.Hit_time.at(hit_index)])\n",
    "\n",
    "\n",
    "def track_cov_propagation(track_popt, track_pcov, dt, dt_err_add=0):\n",
    "    x0,y0,z0,vx,vy,vz,t0 = track_popt\n",
    "    \n",
    "    jac=np.array([[1,   0,   0,   dt,  0,   0,   -vx],\n",
    "                  [0,   1,   0,    0, dt,   0,   -vy],\n",
    "                  [0,   0,   1,    0,  0,  dt,   -vz]])\n",
    "    \n",
    "    # Times the Jacobian, and add uncertainty from the time\n",
    "    point_pcov = jac@track_pcov@jac.T + np.diag([(vx*dt_err_add)**2, (vy*dt_err_add)**2, (vz*dt_err_add)**2])\n",
    "    # point_pcov_inv=  np.linalg.inv(point_pcov)+ np.diag([1/(vx*dt_err_add)**2, 1/(vy*dt_err_add)**2, 1/(vz*dt_err_add)**2])\n",
    "    \n",
    "    return point_pcov\n",
    "\n",
    "def get_hit_uncertainty(hit, digi_layer_id=None):\n",
    "    hit_uncertainty = np.array(detector.Layer().uncertainty(digi_layer_id))\n",
    "    if digi_layer_id<10:\n",
    "        hit_uncertainty=np.array(hit_uncertainty)*100 # turn to cm, in CMS coordinate\n",
    "    else:\n",
    "        hit_uncertainty=np.array([hit_uncertainty[0]*100, hit_uncertainty[2]*100, hit_uncertainty[1]*100])\n",
    "\n",
    "    return hit_uncertainty\n",
    "\n",
    "def track_point_propagation(track_popt,dt):\n",
    "    x0,y0,z0,vx,vy,vz,t0 = track_popt\n",
    "    return [x0+vx*dt,y0+vy*dt,z0+vz*dt, t0+dt]\n",
    "\n",
    "def chi2_distance_to(track_param, track_cov, point_xyz, point_t, point_t_err = 0):\n",
    "    \"\"\"\n",
    "    track_param: (x0,y0,z0, vx,vy,vz, t)\n",
    "    \"\"\"\n",
    "    dt = point_t - track_param[6]\n",
    "    point_location = track_point_propagation(track_param, dt)\n",
    "    \n",
    "    residual_vector = point_xyz[:3] - np.array(point_location[:3])\n",
    "    \n",
    "    # point_pcov_inv = track_cov_propagation(track_param, track_cov, dt, dt_err_add=point_t_err)\n",
    "    # chi2 = residual_vector.T @ point_pcov_inv @ residual_vector;\n",
    "    \n",
    "    point_pcov = track_cov_propagation(track_param, track_cov, dt, dt_err_add=point_t_err)\n",
    "    chi2 = residual_vector.T @ np.linalg.inv(point_pcov) @ residual_vector;\n",
    "    return chi2\n",
    "\n",
    "\n",
    "\n",
    "# def chi2_distance_to(track_param, track_cov, point_xyz,t):\n",
    "#     \"\"\"\n",
    "#     track_param: (x0,y0,z0, vx,vy,vz, t)\n",
    "#     \"\"\"\n",
    "#     _x,_y,_z= point_xyz;\n",
    "#     x0,y0,z0, vx,vy,vz, t0 = track_param\n",
    "#     dy = _y-y0\n",
    "    \n",
    "#     # Transform track covariance to covariance of (x,y,z)\n",
    "#     jac=np.array([[     1, -vx/vy,    0,         dy/vy,    -vx*dy/(vy*vy),        0,        0],\n",
    "#           [ 0, -vz/vy,  1,            0,    -vz*dy/(vy*vy),    dy/vy,        0],\n",
    "#             [0,  -1/vy,     0,            0,       -dy/(vy*vy),        0,         1]])\n",
    "#     CovMatrix_vertex = jac @ track_cov @ jac.transpose();\n",
    "    \n",
    "#     residual_vector = np.array([_x - (x0+vx*dy/vy),     _z- (z0+vz*dy/vy),        t- (t0+dy/vy)])\n",
    "#     chi2 = residual_vector.transpose() @np.linalg.inv(CovMatrix_vertex)@residual_vector;\n",
    "    \n",
    "#     return chi2\n",
    "\n",
    "# def chi2_distance_to_2(track_param, track_cov, point_xyz,t):\n",
    "#     \"\"\"\n",
    "#     track_param: (x0,y0,z0, vx,vy,vz, t)\n",
    "#     \"\"\"\n",
    "#     _x,_y,_z= point_xyz;\n",
    "#     x0,y0,z0, vx,vy,vz, t0 = track_param\n",
    "#     dt = t-t0\n",
    "    \n",
    "#     # Transform track covariance to covariance of (x,y,z)\n",
    "#     jac=np.array([[     1, 0,    0,         dt,   0,        0,        -vx],\n",
    "#                   [ 0, 1,  0,            0,    dt,    0,        -vy],\n",
    "#                     [0, 0,     1,            0,       0,        dt,         -vz]])\n",
    "#     CovMatrix_vertex = jac @ track_cov @ jac.transpose();\n",
    "    \n",
    "#     residual_vector = np.array([_x - (x0+vx*dt),     _y- (y0+vy*dt),    _z- (z0+vz*dt)])\n",
    "#     chi2 = residual_vector.transpose() @np.linalg.inv(CovMatrix_vertex)@residual_vector;\n",
    "    \n",
    "#     return chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f4bf4b-c651-4a86-8f3d-6fc039530b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_km_alltracks_old(filename, results_fit = None, tree_name=\"integral_tree\", truth_pids = [13,13], nevents=-1):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ---\n",
    "    nevents: \n",
    "      -1: all events\n",
    "      (start, stop) from start to stop\n",
    "    \"\"\"\n",
    "    \n",
    "    if results_fit is None:\n",
    "        results_fit={}\n",
    "\n",
    "        \n",
    "    results_fit[\"Entry\"]=[]               # ROOT event entry number\n",
    "    results_fit[\"ndigi\"]=[]               # Total number of digitized hits\n",
    "    results_fit[\"Digi_track_id\"]=[]\n",
    "    results_fit[\"mask_recon_success_track\"]=[]    # Boolean mask \n",
    "    results_fit[\"mask_recon_success_vertex\"]=[]   # Boolean mask \n",
    "    results_fit[\"mask_reconstructible_vertex\"]=[]   # Boolean mask, if an event has two tracks with 4+ hits. The track is required to be from the direct input\n",
    "    results_fit[\"mask_reconstructible2_vertex\"]=[]   # Boolean mask, if an event has two tracks with 4+ hits. The track can be from any particle.  \n",
    "\n",
    "    \n",
    "    results_fit[\"tracks_truth\"]=[]\n",
    "    results_fit[\"tracks_truth_n\"]=[]\n",
    "    results_fit[\"tracks_truth_nlayer\"]=[]\n",
    "    results_fit[\"tracks_truth_pdgids\"]=[]\n",
    "    \n",
    "    results_fit[\"tracks_recon\"]=[]\n",
    "    results_fit[\"tracks_recon_n\"]=[]\n",
    "    results_fit[\"tracks_recon_error\"]=[]          # KF parameter uncertainty. Already taken sqrt()\n",
    "    results_fit[\"tracks_ndigi\"]=[]          #  number of digitized hits in the track\n",
    "    results_fit[\"tracks_ndigi_false\"]=[]    #  number of digitized hits in the track that are not from the truth\n",
    "    results_fit[\"tracks_purity\"]=[]         # List of PDG id of hits in this track \n",
    "    results_fit[\"tracks_pdgids\"]=[]         # List of PDG id of hits in this track \n",
    "    results_fit[\"tracks_chi2\"]=[]           # KF fit chi2\n",
    "    \n",
    "    results_fit[\"vertices_truth\"]=[]\n",
    "    results_fit[\"vertices_ntrack\"]=[]\n",
    "    results_fit[\"vertices_ntrack_truth\"]=[]\n",
    "    results_fit[\"vertices_recon\"]=[]\n",
    "    results_fit[\"vertices_recon_n\"]=[]\n",
    "    results_fit[\"vertices_recon_error\"]=[]\n",
    "    results_fit[\"vertices_recon_cov\"]=[]\n",
    "    results_fit[\"vertices_chi2\"]=[]\n",
    "    \n",
    "\n",
    "\n",
    "    ev = event.Event(filename, 0, tree_name=tree_name)\n",
    "    Tree=ev.Tree\n",
    "    nevents_total = int(ev.Tree.GetEntries())\n",
    "    cut=cutflow.sample_space(\"\")\n",
    "    \n",
    "    if nevents==-1:\n",
    "        nevents = [0, nevents_total]\n",
    "    elif type(nevents) is int:\n",
    "        if nevents_total<nevents:\n",
    "            print(f\"Requested events exceed total {nevents_total}\")\n",
    "        nevents = [0, min(nevents,nevents_total)]\n",
    "    else:\n",
    "        if nevents_total<nevents[1]:\n",
    "            print(f\"Requested events exceed total {nevents_total}\")        \n",
    "        nevents = [nevents[0], min(nevents[1],nevents_total)]\n",
    "\n",
    "    for i_event in tqdm(range(nevents[0], nevents[1])):\n",
    "        ev.EventNumber=i_event\n",
    "        ev.Tree.GetEntry(i_event)\n",
    "        ev.ExtractTruthPhysics_list()\n",
    "        \n",
    "        par_km_ndigi = ev.Tree.Digi_x.size()\n",
    "        \n",
    "        results_fit[\"Entry\"].append(i_event)\n",
    "        results_fit[\"ndigi\"].append(par_km_ndigi)\n",
    "        results_fit[\"Digi_track_id\"].append(util.c2list(ev.Tree.Digi_track_id))\n",
    "        ids=np.array(results_fit[\"Digi_track_id\"][-1])\n",
    "        ys = np.array(util.c2list(ev.Tree.Digi_y))\n",
    "        n_reconstructible=0\n",
    "        n_reconstructible2=0\n",
    "        for g4id in range(0,200):\n",
    "            if len(np.unique(ys[ids==g4id]))>=4:\n",
    "                n_reconstructible+=1\n",
    "        for g4id in np.unique(ids):\n",
    "            if len(np.unique(ys[ids==g4id]))>=4:\n",
    "                n_reconstructible2+=1                \n",
    "        results_fit[\"vertices_ntrack_truth\"].append(n_reconstructible)\n",
    "        if n_reconstructible>=2:\n",
    "            results_fit[\"mask_reconstructible_vertex\"].append(True)\n",
    "        else:\n",
    "            results_fit[\"mask_reconstructible_vertex\"].append(False)   \n",
    "        if n_reconstructible2>=2:\n",
    "            results_fit[\"mask_reconstructible2_vertex\"].append(True)\n",
    "        else:\n",
    "            results_fit[\"mask_reconstructible2_vertex\"].append(False)               \n",
    "\n",
    "        # Get truth (speed need to be calculated by hand)\n",
    "        try:\n",
    "            # Truth position and speed\n",
    "            TruthTracks = []\n",
    "            Truths = []\n",
    "            Truth_nlayer = []\n",
    "            Truth_pdgids = []\n",
    "            for track in ev.truthTrackList_list:\n",
    "                if track[4][0] in truth_pids:\n",
    "                    TruthTracks.append(track)\n",
    "                    dt=track[3][1]-track[3][0]\n",
    "                    vx=(track[0][1]-track[0][0])/dt\n",
    "                    vy=(track[1][1]-track[1][0])/dt\n",
    "                    vz=(track[2][1]-track[2][0])/dt\n",
    "                    truth = [track[0][0], track[1][0], track[2][0], track[3][0],vx,vy,vz]  \n",
    "                    Truths.append(truth)\n",
    "                    Truth_nlayer.append(np.abs(cut.in_layer(track[1][-1])-cut.in_layer(track[1][0])))\n",
    "                    Truth_pdgids.append(track[4][0])\n",
    "            \n",
    "            n_truthtracks=len(TruthTracks)\n",
    "            results_fit[\"tracks_truth\"].append(Truths)  \n",
    "            results_fit[\"tracks_truth_n\"].append(n_truthtracks)  \n",
    "            results_fit[\"tracks_truth_nlayer\"].append(Truth_nlayer)  \n",
    "            \n",
    "        except:\n",
    "            n_truthtracks=0\n",
    "            results_fit[\"tracks_truth\"].append([[-9999]])\n",
    "            results_fit[\"tracks_truth_n\"].append(n_truthtracks)  \n",
    "            results_fit[\"tracks_truth_nlayer\"].append([[-9999]])\n",
    "                  \n",
    "        \n",
    "        # If there is reconstruction:\n",
    "        if len(ev.Tree.Track_k_m_z0)==0:\n",
    "            tracks_recon = [[-9990, -9990, -9990, -9990, -9990, -9990, -9990]]\n",
    "            tracks_recon_n = 0\n",
    "            tracks_recon_error = [[-9990, -9990, -9990, -9990, -9990, -9990, -9990]]\n",
    "            tracks_chi2 = [0]\n",
    "            \n",
    "            tracks_ndigi = [0]\n",
    "            tracks_ndigi_false = [0]\n",
    "            tracks_purity = [-999]\n",
    "            tracks_pdgids = [0]\n",
    "            results_fit[\"mask_recon_success_track\"].append(False)\n",
    "            \n",
    "        else:\n",
    "            tracks_recon = []\n",
    "            tracks_recon_n = Tree.Track_k_m_z0.size()\n",
    "            tracks_recon_error = []\n",
    "            tracks_chi2 = []\n",
    "            tracks_ndigi = []\n",
    "            tracks_ndigi_false = []\n",
    "            tracks_purity = []\n",
    "            tracks_pdgids = []            \n",
    "            \n",
    "            \n",
    "            # Select the reconstruction that is closest to truth\n",
    "            track_digi_hit_inds = util.unzip(Tree.Track_k_m_hitIndices)\n",
    "            track_truth_ids = util.unzip(Tree.Track_k_m_ids)\n",
    "            track_digi_hit_len = np.array([len(i) for i in track_digi_hit_inds])\n",
    "            if tracks_recon_n<n_truthtracks:\n",
    "                results_fit[\"mask_recon_success_track\"].append(False)\n",
    "            else:\n",
    "                results_fit[\"mask_recon_success_track\"].append(True)                \n",
    "                \n",
    "            for i_track in range(len(TruthTracks)):\n",
    "                truth = Truths[i_track]\n",
    "\n",
    "                track_chi2s = []\n",
    "                if len(track_digi_hit_inds)>1:\n",
    "                    for track_ind in range(len(track_digi_hit_inds)):\n",
    "                        recon_i = [Tree.Track_k_m_x0.at(track_ind), Tree.Track_k_m_y0.at(track_ind), Tree.Track_k_m_z0.at(track_ind), Tree.Track_k_m_t0.at(track_ind),Tree.Track_k_m_velX.at(track_ind), Tree.Track_k_m_velY.at(track_ind), Tree.Track_k_m_velZ.at(track_ind)]\n",
    "                        recon_i_unc = [Tree.Track_k_m_ErrorX0.at(track_ind), Tree.Track_k_m_ErrorY0.at(track_ind), Tree.Track_k_m_ErrorZ0.at(track_ind), Tree.Track_k_m_ErrorT0.at(track_ind),Tree.Track_k_m_ErrorVx.at(track_ind), Tree.Track_k_m_ErrorVy.at(track_ind), Tree.Track_k_m_ErrorVz.at(track_ind)]\n",
    "                        chi2 = util.chi2_calc(recon_i,truth,recon_i_unc)\n",
    "                        track_chi2s.append(chi2)\n",
    "                    track_ind = int(np.argmin(track_chi2s))\n",
    "                else:\n",
    "                    track_ind=0\n",
    "\n",
    "                tracks_recon.append([ev.Tree.Track_k_m_x0.at(track_ind), ev.Tree.Track_k_m_y0.at(track_ind), ev.Tree.Track_k_m_z0.at(track_ind), ev.Tree.Track_k_m_t0.at(track_ind), ev.Tree.Track_k_m_velX.at(track_ind), ev.Tree.Track_k_m_velY.at(track_ind), ev.Tree.Track_k_m_velZ.at(track_ind)])\n",
    "                tracks_recon_error.append([ev.Tree.Track_k_m_ErrorX0.at(track_ind), ev.Tree.Track_k_m_ErrorY0.at(track_ind), ev.Tree.Track_k_m_ErrorZ0.at(track_ind), ev.Tree.Track_k_m_ErrorT0.at(track_ind), ev.Tree.Track_k_m_ErrorVx.at(track_ind), ev.Tree.Track_k_m_ErrorVy.at(track_ind), ev.Tree.Track_k_m_ErrorVz.at(track_ind)])\n",
    "                tracks_chi2.append(ev.Tree.Track_k_m_smooth_chi_sum.at(track_ind))\n",
    "                \n",
    "                track_hits_inds=track_digi_hit_inds[track_ind]\n",
    "                truth_pid = TruthTracks[i_track][4][0]\n",
    "                truth_track_id = TruthTracks[i_track][6][0]\n",
    "                kalmantrack_truthtrack_ids = track_truth_ids[track_ind]\n",
    "                \n",
    "                tracks_pdgids.append([ev.Tree.Digi_pdg_id.at(i) for i in track_hits_inds])\n",
    "                tracks_ndigi.append(len(track_hits_inds))\n",
    "                tracks_ndigi_false.append(sum(np.array(kalmantrack_truthtrack_ids)!=truth_track_id))\n",
    "                tracks_purity.append(1-tracks_ndigi_false[-1]/tracks_ndigi[-1])\n",
    "                \n",
    "        # Vertex========================================================\n",
    "        if len(ev.Tree.Vertex_k_m_x)==0:\n",
    "            vertex_recon = [[0]]\n",
    "            vertex_recon_n=0\n",
    "            vertex_recon_error=[[0]]\n",
    "            vertices_chi2=[[0]]\n",
    "            results_fit[\"mask_recon_success_vertex\"].append(False) \n",
    "        else:\n",
    "            results_fit[\"mask_recon_success_vertex\"].append(True) \n",
    "            vertex_recon=[]\n",
    "            vertex_recon_n = Tree.Vertex_k_m_x.size()\n",
    "            vertex_recon_error=[]\n",
    "            vertex_recon_cov=[]\n",
    "            vertices_chi2=[]\n",
    "            for iv in range(vertex_recon_n):\n",
    "                v=[Tree.Vertex_k_m_x.at(iv),Tree.Vertex_k_m_y.at(iv),Tree.Vertex_k_m_z.at(iv),Tree.Vertex_k_m_t.at(iv)]\n",
    "                vertex_recon.append(v)\n",
    "                verr=[Tree.Vertex_k_m_ErrorX.at(iv),Tree.Vertex_k_m_ErrorY.at(iv),Tree.Vertex_k_m_ErrorZ.at(iv),Tree.Vertex_k_m_ErrorT.at(iv)]\n",
    "                vertex_recon_error.append(verr)  \n",
    "                vcov=[[Tree.Vertex_k_m_ErrorX.at(iv)**2, Tree.Vertex_k_m_cov_x_y.at(iv), Tree.Vertex_k_m_cov_x_z.at(iv), Tree.Vertex_k_m_cov_t_x.at(iv)],\n",
    "                      [Tree.Vertex_k_m_cov_x_y.at(iv),   Tree.Vertex_k_m_ErrorY.at(iv)**2, Tree.Vertex_k_m_cov_y_z.at(iv), Tree.Vertex_k_m_cov_t_y.at(iv)],\n",
    "                      [Tree.Vertex_k_m_cov_x_z.at(iv),   Tree.Vertex_k_m_cov_y_z.at(iv), Tree.Vertex_k_m_ErrorZ.at(iv)**2, Tree.Vertex_k_m_cov_t_z.at(iv)],\n",
    "                      [Tree.Vertex_k_m_cov_t_x.at(iv),   Tree.Vertex_k_m_cov_t_y.at(iv), Tree.Vertex_k_m_cov_t_z.at(iv), Tree.Vertex_k_m_ErrorT.at(iv)**2]]\n",
    "                vertex_recon_cov.append(vcov)\n",
    "                vertices_chi2.append(Tree.vertex_k_m_chi2.at(iv))\n",
    "                \n",
    "        vertex_truth_cms = [Tree.GenParticle_y.at(1)*0.1, -Tree.GenParticle_z.at(1)*0.1 + 8547, Tree.GenParticle_x.at(1)*0.1]\n",
    "        vertex_track_inds = util.unzip(Tree.Vertex_k_m_trackIndices)\n",
    "        vertex_ntrack = [len(ii) for ii in vertex_track_inds]\n",
    "        \n",
    "        \n",
    "        results_fit[\"tracks_recon\"].append(tracks_recon)\n",
    "        results_fit[\"tracks_recon_n\"].append(tracks_recon_n)\n",
    "        results_fit[\"tracks_recon_error\"].append(np.sqrt(tracks_recon_error))\n",
    "        results_fit[\"tracks_chi2\"].append(tracks_chi2)\n",
    "        results_fit[\"tracks_ndigi\"].append(tracks_ndigi)\n",
    "        results_fit[\"tracks_ndigi_false\"].append(tracks_ndigi_false)\n",
    "        results_fit[\"tracks_purity\"].append(tracks_purity)\n",
    "        results_fit[\"tracks_pdgids\"].append(tracks_pdgids)\n",
    "        \n",
    "        results_fit[\"vertices_truth\"].append(vertex_truth_cms)\n",
    "        results_fit[\"vertices_ntrack\"].append(vertex_ntrack)\n",
    "        results_fit[\"vertices_recon\"].append(vertex_recon)\n",
    "        results_fit[\"vertices_recon_n\"].append(vertex_recon_n)\n",
    "        results_fit[\"vertices_recon_error\"].append(vertex_recon_error)\n",
    "        results_fit[\"vertices_recon_cov\"].append(vertex_recon_cov)\n",
    "        results_fit[\"vertices_chi2\"].append(vertices_chi2)\n",
    "        \n",
    "        \n",
    "    for key in [\"tracks_truth_n\",\"tracks_recon_n\",\"mask_recon_success_track\", \"mask_recon_success_vertex\",\"vertices_recon_n\", \"vertices_ntrack_truth\"]:\n",
    "        results_fit[key]=np.array(results_fit[key])\n",
    "        \n",
    "        \n",
    "    return results_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7465b8-bdca-4314-a0b3-611f3bc129ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_vertex(filename):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "    [[x, y, z, px, py, pz],[x, y, z, px, py, pz],...]\n",
    "    \"\"\"\n",
    "    vertices = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            if \"#\" in line:\n",
    "                continue\n",
    "            else:\n",
    "                line = line.split()\n",
    "                if len(line)>0 and line[0] == \"n\":\n",
    "                    while True:\n",
    "                        line2 = f.readline()\n",
    "                        if \"#\" in line2:\n",
    "                            continue                           \n",
    "                        line2 = line2.split()\n",
    "                        if len(line2)>0:\n",
    "                            break\n",
    "                    vertex = [float(line2[1]), float(line2[2]), float(line2[3]), float(line[6]), float(line[7]), float(line[8])] # x, y, z, px, py, pz\n",
    "                    vertices.append(vertex)\n",
    "                else:\n",
    "                    continue\n",
    "    return np.array(vertices)\n",
    "\n",
    "\n",
    "def read_raw_vertex_weight(filename):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "    [[x, y, z, px, py, pz],[x, y, z, px, py, pz],...]\n",
    "    \"\"\"\n",
    "    vertices = []\n",
    "    weights = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            if \"#\" in line:\n",
    "                if \"### weight\" in line:\n",
    "                    line = line.split()\n",
    "                    weights.append([float(line[2]), float(line[3]), float(line[4])])\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                line = line.split()\n",
    "                if len(line)>0 and line[0] == \"n\":\n",
    "                    while True:\n",
    "                        line2 = f.readline()\n",
    "                        if \"#\" in line2:\n",
    "                            continue                           \n",
    "                        line2 = line2.split()\n",
    "                        if len(line2)>0:\n",
    "                            break\n",
    "                    vertex = [float(line2[1]), float(line2[2]), float(line2[3]), float(line[6]), float(line[7]), float(line[8])] # x, y, z, px, py, pz\n",
    "                    vertices.append(vertex)\n",
    "                else:\n",
    "                    continue\n",
    "    return np.array(vertices), np.array(weights)\n",
    "\n",
    "\n",
    "def read_raw_vertex_ntracks(filename):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "    list of number of tracks in each vertex\n",
    "    \"\"\"\n",
    "    ntracks = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            if \"#\" in line:\n",
    "                continue\n",
    "            else:\n",
    "                line = line.split()\n",
    "                if len(line)>0:\n",
    "                    if line[0] == \"n\":\n",
    "                        ntracks.append(0)                \n",
    "                    else:\n",
    "                        ntracks[-1]+=1\n",
    "    return np.array(ntracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5e17c8-d437-4b58-a98a-76d9d7cebb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SMS_decay_types(mX):\n",
    "    m_mu = 0.1057\n",
    "    m_pi = 0.139    \n",
    "    if float(mX)<2*m_mu:\n",
    "        Decay_types = [\"ee\"]\n",
    "    elif float(mX)<2*m_pi:\n",
    "        Decay_types = [\"mumu\"]\n",
    "    elif float(mX)<0.7:\n",
    "        Decay_types = [\"mumu\",\"pipi\"]\n",
    "    elif float(mX)<0.98:\n",
    "        Decay_types = [\"mumu\",\"hadrons0.7to0.98gev\"]\n",
    "    elif float(mX)<2:\n",
    "        Decay_types = [\"mumu\",\"hadrons1to2gev\"]\n",
    "    elif float(mX)<3.65:\n",
    "        Decay_types = [\"gg\",\"ss\",\"mumu\"]  \n",
    "    elif float(mX)<3.8:\n",
    "        Decay_types = [\"gg\",\"ss\",\"mumu\",\"tautau\",]          \n",
    "    elif float(mX)<5:\n",
    "        Decay_types = [\"gg\",\"ss\",\"mumu\",\"tautau\", \"cc\"]    \n",
    "        \n",
    "    return Decay_types"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SCDMS V04-07",
   "language": "python",
   "name": "scdms_v04-07"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
